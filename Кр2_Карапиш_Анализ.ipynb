{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAPN5mSRmgd4"
      },
      "source": [
        "### КР2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNXTnmIKmgd_"
      },
      "source": [
        "### Бустинг. - 6 баллов\n",
        "В существующий код бустинга добавьте возможность ранней остановки обучения.\n",
        "должны быть учтены:\n",
        "1) Наличие валидационного датасета (либо разделение должно быть внутри класса, либо вне его, а в обучении новый набор будет подаваться отдельной парой)\n",
        "2) Кастомная метрика или лосс для оствновки. Должна передаваться в виде доп. параметра. Дефолт - лосс функция для расчета градиента.\n",
        "3) Укажите, сколько должно пройти итераций для ранней остановки.\n",
        "4) После обучения должно вернуться лучшее состояние модели по валидационной выборке, а не то, которое было достинуто при остановке обучения.\n",
        "\n",
        "Для обучения используйте тот же датасет, что использовался на 8 семинаре (house_price_regression_dataset).\n",
        "1 и 3 пункты обязательны - 3 балла. 2 пункт - 1 балл (при недефолтной реализации). 4 пункт - 2 балла."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "bjOn21LamgeA"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "### Собственная реализация\n",
        "class MyGradientRegressor:\n",
        "    def __init__(self, n_estimators: int = 300, max_depth: int = 3, lr: float = 0.1):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.lr = lr\n",
        "        self.estimators = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        self.estimators = []\n",
        "        predictions = 0\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            new_model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "            new_target = -2 * (predictions - y_train)\n",
        "            new_model.fit(X_train, new_target)\n",
        "            predictions += self.lr * new_model.predict(X_train)\n",
        "            self.estimators.append(new_model)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = np.array(X_test)\n",
        "        curr_pred = 0\n",
        "        for est in self.estimators:\n",
        "            curr_pred += self.lr * est.predict(X_test)\n",
        "\n",
        "        return curr_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNewGradientRegressor:\n",
        "    def __init__(self, n_estimators: int = 300, max_depth: int = 3, lr: float = 0.1,\n",
        "                 stop: int = 10, scoring_metric=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.lr = lr\n",
        "        self.estimators = []\n",
        "        self.best_estimator = None\n",
        "        self.stop = stop\n",
        "        if scoring_metric is not None:\n",
        "          self.scoring_metric = scoring_metric\n",
        "        else: self.scoring_metric = self.loss\n",
        "        self.best_score = 0\n",
        "\n",
        "    def loss(self, y, y_pred):\n",
        "        return np.mean((y - y_pred) ** 2)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        self.estimators = []\n",
        "        predictions = np.zeros(y_train.shape)\n",
        "        stop_count = 0\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            new_model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "            new_target = -2 * (predictions - y_train)\n",
        "            new_model.fit(X_train, new_target)\n",
        "            predictions += self.lr * new_model.predict(X_train)\n",
        "            self.estimators.append(new_model)\n",
        "\n",
        "            if X_val is not None and y_val is not None:\n",
        "                X_val = np.array(X_val)\n",
        "                y_val = np.array(y_val)\n",
        "                val_predictions = self.predict(X_val)\n",
        "                score = self.scoring_metric(y_val, val_predictions)\n",
        "\n",
        "                if score < self.best_score:\n",
        "                    self.best_score = score\n",
        "                    self.best_estimator = new_model\n",
        "                    stop_count = 0\n",
        "                else:\n",
        "                    stop_count += 1\n",
        "                if stop_count >= self.stop:\n",
        "                    break\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = np.array(X_test)\n",
        "        curr_pred = np.zeros(X_test.shape[0])\n",
        "        for est in self.estimators:\n",
        "            curr_pred += self.lr * est.predict(X_test)\n",
        "\n",
        "        return curr_pred"
      ],
      "metadata": {
        "id": "JTIRCfYXn9va"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_csv(\"house_price_regression_dataset.csv\")\n",
        "\n",
        "X = data.drop(columns=[\"House_Price\"])\n",
        "y = data[\"House_Price\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "X_train.reset_index(inplace=True)\n",
        "X_test.reset_index(inplace=True)\n",
        "y_train = y_train.reset_index()[\"House_Price\"]\n",
        "y_test = y_test.reset_index()[\"House_Price\"]"
      ],
      "metadata": {
        "id": "u7pg1upZm-6U"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Старый вариант"
      ],
      "metadata": {
        "id": "Nbu6MLpTwWcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "my_model = MyGradientRegressor(n_estimators=300, max_depth=3, lr=0.1)\n",
        "my_model.fit(X_train, y_train)\n",
        "\n",
        "pred = my_model.predict(X_test)\n",
        "mean_absolute_error(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGrvCQThocEj",
        "outputId": "a611e2f2-3a76-4baf-83d0-d1ba673fccb5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12370.582471045378"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Новый вариант"
      ],
      "metadata": {
        "id": "jWukxb1FwYUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = MyNewGradientRegressor(n_estimators=300, max_depth=3, lr=0.1, stop=50)\n",
        "my_model.fit(X_train, y_train, X_val=X_test, y_val=y_test)\n",
        "\n",
        "pred = my_model.predict(X_test)\n",
        "mean_absolute_error(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IMQ7Pfqo3c4",
        "outputId": "ce59bfb4-9d82-48e3-874e-467412a114b1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12859.19161059405"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8Ai6DzBmgeH"
      },
      "source": [
        "### Стекинг - 4 балла\n",
        "В текущей реализации в качестве признаков для метамодели используются предсказания базовых моделей.\n",
        "Ваша задача добавить возможность дополнительно учитывать исходные данные в качестве признаков (гиперпараметр).\n",
        "Метапризнаки как доп. фичи к основным.\n",
        "При этом на основные признаки добавляется воможность расчета полиномиальных признаков (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
        "\n",
        "Для тестирования используйте тот же датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "WLK9tAy6mgeI"
      },
      "outputs": [],
      "source": [
        "class Stacking:\n",
        "    def __init__(self, estimators, meta_estimator, folds=5):\n",
        "        self.estimators = estimators\n",
        "        self.meta_estimator = meta_estimator\n",
        "        self.folds = folds\n",
        "        self.meta_train = []\n",
        "\n",
        "    def _fit_estimator(self, estimator, X_train, y_train):\n",
        "        kf = KFold(n_splits=self.folds, shuffle=True)\n",
        "        train_fold_indices = []\n",
        "        test_fold_indices = []\n",
        "        test_fold_predicts = []\n",
        "\n",
        "        for train_idx, test_idx in kf.split(X_train):\n",
        "            train_fold_indices.extend(train_idx)\n",
        "            test_fold_indices.extend(test_idx)\n",
        "\n",
        "            estimator.fit(X_train[train_idx], y_train[train_idx])\n",
        "            test_fold_predicts.extend(estimator.predict(X_train[test_idx]))\n",
        "\n",
        "        estimator.fit(X_train, y_train)\n",
        "        self.meta_train.append(np.array(test_fold_predicts)[np.argsort(test_fold_indices)])\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        self.meta_train = []\n",
        "\n",
        "        for estimator in self.estimators:\n",
        "            self._fit_estimator(estimator, X_train, y_train)\n",
        "\n",
        "        self.meta_train = np.array(self.meta_train).transpose()\n",
        "        self.meta_estimator.fit(self.meta_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = np.array(X_test)\n",
        "        meta_features = np.array([estimator.predict(X_test) for estimator in self.estimators]).transpose()\n",
        "        return self.meta_estimator.predict(meta_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "class NewStacking:\n",
        "    def __init__(self, estimators, meta_estimator, folds=5, use_features=False, degree=1):\n",
        "        self.estimators = estimators\n",
        "        self.meta_estimator = meta_estimator\n",
        "        self.folds = folds\n",
        "        self.use_features = use_features\n",
        "        self.degree = degree\n",
        "        self.meta_train = []\n",
        "\n",
        "    def _fit_estimator(self, estimator, X_train, y_train):\n",
        "        kf = KFold(n_splits=self.folds, shuffle=True)\n",
        "        train_fold_indices = []\n",
        "        test_fold_indices = []\n",
        "        test_fold_predicts = []\n",
        "\n",
        "        for train_idx, test_idx in kf.split(X_train):\n",
        "            train_fold_indices.extend(train_idx)\n",
        "            test_fold_indices.extend(test_idx)\n",
        "\n",
        "            estimator.fit(X_train[train_idx], y_train[train_idx])\n",
        "            test_fold_predicts.extend(estimator.predict(X_train[test_idx]))\n",
        "\n",
        "        estimator.fit(X_train, y_train)\n",
        "        self.meta_train.append(np.array(test_fold_predicts)[np.argsort(test_fold_indices)])\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        self.meta_train = []\n",
        "\n",
        "        if self.use_features:\n",
        "            poly = PolynomialFeatures(degree=self.degree)\n",
        "            X_train_poly = poly.fit_transform(X_train)\n",
        "        else:\n",
        "            X_train_poly = X_train\n",
        "\n",
        "        for estimator in self.estimators:\n",
        "            self._fit_estimator(estimator, X_train_poly, y_train)\n",
        "\n",
        "        self.meta_train = np.array(self.meta_train).transpose()\n",
        "        self.meta_estimator.fit(self.meta_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test = np.array(X_test)\n",
        "\n",
        "        if self.use_features:\n",
        "            poly = PolynomialFeatures(degree=self.degree)\n",
        "            X_test_poly = poly.fit_transform(X_test)\n",
        "        else:\n",
        "            X_test_poly = X_test\n",
        "\n",
        "        meta_features = np.array([estimator.predict(X_test_poly) for estimator in self.estimators]).transpose()\n",
        "        return self.meta_estimator.predict(meta_features)\n"
      ],
      "metadata": {
        "id": "QyDjFMxYsNyN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "data = pd.read_csv(\"house_price_regression_dataset.csv\")\n",
        "\n",
        "X = data.drop(columns=[\"House_Price\"])\n",
        "y = data[\"House_Price\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "X_train.reset_index(inplace=True)\n",
        "X_test.reset_index(inplace=True)\n",
        "y_train = y_train.reset_index()[\"House_Price\"]\n",
        "y_test = y_test.reset_index()[\"House_Price\"]"
      ],
      "metadata": {
        "id": "XklL9iF8tL0W"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Старый вариант"
      ],
      "metadata": {
        "id": "y3yUiMSBwO1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Stacking(\n",
        "    estimators=[\n",
        "        LinearRegression(),\n",
        "        DecisionTreeRegressor(max_depth=3),\n",
        "        XGBRegressor(n_estimators=100, max_depth=3),\n",
        "    ],\n",
        "    meta_estimator=LinearRegression(),\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgg2huMFtKPh",
        "outputId": "f91c835b-a8d4-405e-a0b3-2bbe44b1e53a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7830.853761245918"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Новый вариант"
      ],
      "metadata": {
        "id": "QKj74dFVwRdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NewStacking(\n",
        "    estimators=[\n",
        "        LinearRegression(),\n",
        "        DecisionTreeRegressor(max_depth=3),\n",
        "        XGBRegressor(n_estimators=100, max_depth=3),\n",
        "    ],\n",
        "    meta_estimator=LinearRegression(),\n",
        "    use_features=True,\n",
        "    degree=2\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcVglGs0th-h",
        "outputId": "137222ee-dc6a-46e4-afe1-03770f801407"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8028.888204153737"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fc5cKphvtnQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}